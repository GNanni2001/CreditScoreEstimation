{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nanni\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pgmpy.models as models\n",
    "import networkx as nx\n",
    "from pgmpy.inference import VariableElimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>FAIKR module 3 PROJECT</h2>\n",
    "<p>The dataset considered is about the earnings and the expenses of 1000 people, with informations about their Credit Score, the objective of this project is to try to define a Bayesian Network that can describe the causal links between the expenses, the earnings and the other factors considered in this analisys.</p>\n",
    "<p>the dataset considered is available at <a href=\"https://www.kaggle.com/datasets/conorsully1/credit-score\">this link</a> on kaggle.com.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['INCOME', 'SAVINGS', 'DEBT', 'R_SAVINGS_INCOME', 'R_DEBT_INCOME',\n",
       "       'R_DEBT_SAVINGS', 'T_CLOTHING_12', 'T_CLOTHING_6', 'R_CLOTHING',\n",
       "       'R_CLOTHING_INCOME', 'R_CLOTHING_SAVINGS', 'R_CLOTHING_DEBT',\n",
       "       'T_EDUCATION_12', 'T_EDUCATION_6', 'R_EDUCATION', 'R_EDUCATION_INCOME',\n",
       "       'R_EDUCATION_SAVINGS', 'R_EDUCATION_DEBT', 'T_ENTERTAINMENT_12',\n",
       "       'T_ENTERTAINMENT_6', 'R_ENTERTAINMENT', 'R_ENTERTAINMENT_INCOME',\n",
       "       'R_ENTERTAINMENT_SAVINGS', 'R_ENTERTAINMENT_DEBT', 'T_FINES_12',\n",
       "       'T_FINES_6', 'R_FINES', 'R_FINES_INCOME', 'R_FINES_SAVINGS',\n",
       "       'R_FINES_DEBT', 'T_GAMBLING_12', 'T_GAMBLING_6', 'R_GAMBLING',\n",
       "       'R_GAMBLING_INCOME', 'R_GAMBLING_SAVINGS', 'R_GAMBLING_DEBT',\n",
       "       'T_GROCERIES_12', 'T_GROCERIES_6', 'R_GROCERIES', 'R_GROCERIES_INCOME',\n",
       "       'R_GROCERIES_SAVINGS', 'R_GROCERIES_DEBT', 'T_HEALTH_12', 'T_HEALTH_6',\n",
       "       'R_HEALTH', 'R_HEALTH_INCOME', 'R_HEALTH_SAVINGS', 'R_HEALTH_DEBT',\n",
       "       'T_HOUSING_12', 'T_HOUSING_6', 'R_HOUSING', 'R_HOUSING_INCOME',\n",
       "       'R_HOUSING_SAVINGS', 'R_HOUSING_DEBT', 'T_TAX_12', 'T_TAX_6', 'R_TAX',\n",
       "       'R_TAX_INCOME', 'R_TAX_SAVINGS', 'R_TAX_DEBT', 'T_TRAVEL_12',\n",
       "       'T_TRAVEL_6', 'R_TRAVEL', 'R_TRAVEL_INCOME', 'R_TRAVEL_SAVINGS',\n",
       "       'R_TRAVEL_DEBT', 'T_UTILITIES_12', 'T_UTILITIES_6', 'R_UTILITIES',\n",
       "       'R_UTILITIES_INCOME', 'R_UTILITIES_SAVINGS', 'R_UTILITIES_DEBT',\n",
       "       'T_EXPENDITURE_12', 'T_EXPENDITURE_6', 'R_EXPENDITURE',\n",
       "       'R_EXPENDITURE_INCOME', 'R_EXPENDITURE_SAVINGS', 'R_EXPENDITURE_DEBT',\n",
       "       'CAT_GAMBLING', 'CAT_DEBT', 'CAT_CREDIT_CARD', 'CAT_MORTGAGE',\n",
       "       'CAT_SAVINGS_ACCOUNT', 'CAT_DEPENDENTS', 'CREDIT_SCORE', 'DEFAULT',\n",
       "       'LIFESTYLE'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "partial_url='./credit_score_dataset'\n",
    "df=pd.read_csv(partial_url+'/credit_score.csv')\n",
    "df=df.drop('CUST_ID', axis=1)\n",
    "mcl=40000 #mean cost of life in the U.S.A.\n",
    "df['LIFESTYLE']=(df['INCOME']+df['SAVINGS']-df['T_EXPENDITURE_12'])/mcl\n",
    "display(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting non useful columns\n",
    "transactions=['GROCERIES', 'CLOTHING', 'HOUSING', 'EDUCATION', 'HEALTH', 'TRAVEL', 'ENTERTAINMENT', 'GAMBLING', 'UTILITIES', 'TAX', 'FINES', 'EXPENDITURE']\n",
    "for el in transactions:\n",
    "    label='T_'+el+'_6'\n",
    "    ratio='R_'+el\n",
    "    df=df.drop(label, axis=1)\n",
    "    df=df.drop(ratio, axis=1)\n",
    "df=df.drop(['R_SAVINGS_INCOME', 'R_DEBT_INCOME', 'R_DEBT_SAVINGS', 'R_CLOTHING_INCOME', 'R_CLOTHING_SAVINGS', 'R_CLOTHING_DEBT', \n",
    "         'R_EDUCATION_INCOME', 'R_EDUCATION_SAVINGS', 'R_EDUCATION_DEBT', 'R_ENTERTAINMENT_INCOME', 'R_ENTERTAINMENT_SAVINGS',\n",
    "         'R_ENTERTAINMENT_DEBT', 'R_FINES_INCOME', 'R_FINES_SAVINGS', 'R_FINES_DEBT', 'R_GROCERIES_INCOME', 'R_GROCERIES_SAVINGS',\n",
    "         'R_GROCERIES_DEBT', 'R_HEALTH_INCOME', 'R_HEALTH_SAVINGS', 'R_HEALTH_DEBT', 'R_HOUSING_INCOME', 'R_HOUSING_SAVINGS',\n",
    "         'R_HOUSING_DEBT', 'R_TAX_INCOME', 'R_TAX_SAVINGS', 'R_TAX_DEBT', 'R_TRAVEL_INCOME', 'R_TRAVEL_SAVINGS', 'R_TRAVEL_DEBT',\n",
    "         'R_UTILITIES_INCOME', 'R_UTILITIES_SAVINGS', 'R_UTILITIES_DEBT', 'T_GAMBLING_12', 'R_GAMBLING_INCOME', 'R_GAMBLING_SAVINGS',\n",
    "         'R_GAMBLING_DEBT', 'T_TAX_12', 'T_FINES_12', 'CAT_DEBT','R_EXPENDITURE_INCOME', 'R_EXPENDITURE_SAVINGS',\n",
    "         'R_EXPENDITURE_DEBT','T_UTILITIES_12','T_EXPENDITURE_12'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>After dropping the columns considered not relevant in the network is necessary to map the values discretizing for every column.<br>We will consider some data as reference to define the ranges, trying to mantain a fair ammount of elements for range to reduce errors due to few informations.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_credit_score(value):\n",
    "    if value<580:\n",
    "        return 'Poor'\n",
    "    if value<670:\n",
    "        return 'Fair'\n",
    "    if value<740:\n",
    "        return 'Good'\n",
    "    else:\n",
    "        return 'Very Good'\n",
    "def map_savings(value):\n",
    "    if value==0:\n",
    "        return 'Zero'\n",
    "    if value<300000:\n",
    "        return 'Very Low'\n",
    "    if value<600000:\n",
    "        return 'Low'\n",
    "    if value<1200000:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'\n",
    "def map_income(value):\n",
    "    if value==0:\n",
    "        return 'Zero'\n",
    "    if value<40000:\n",
    "        return 'Very Low'\n",
    "    if value<100000:\n",
    "        return 'Medium'\n",
    "    if value<200000:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'\n",
    "def map_debt(value):\n",
    "    if value==0:\n",
    "        return 'Zero'\n",
    "    if value<50000:\n",
    "        return 'Very Low'\n",
    "    if value<200000:\n",
    "        return 'Medium'\n",
    "    if value<750000:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'    \n",
    "def map_groceries(value):\n",
    "    if value<4000:\n",
    "        return 'Very Low'\n",
    "    if value<12000:\n",
    "        return 'Medium'\n",
    "    if value<20000:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'\n",
    "def map_clothing(value):\n",
    "    if value<1000:\n",
    "        return 'Low'\n",
    "    if value<5000:\n",
    "        return 'Medium'\n",
    "    if value<10000:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'\n",
    "def map_education(value):\n",
    "    if value==0:\n",
    "        return 'Zero'\n",
    "    if value<2000:\n",
    "        return 'Low'\n",
    "    if value<6000:\n",
    "        return 'Medium'\n",
    "    if value<12000:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'\n",
    "def map_entertainment(value):\n",
    "    if value==0:\n",
    "        return 'Zero'\n",
    "    if value<3000:\n",
    "        return 'Low'\n",
    "    if value<6000:\n",
    "        return 'Medium'\n",
    "    if value<18000:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'\n",
    "def map_health(value):\n",
    "    if value==0:\n",
    "        return 'Zero'\n",
    "    if value<3000:\n",
    "        return 'Low'\n",
    "    if value<6000:\n",
    "        return 'Medium'\n",
    "    if value<12000:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'\n",
    "def map_housing(value):\n",
    "    if value==0:\n",
    "        return 'Zero'\n",
    "    if value<3000:\n",
    "        return 'Low'\n",
    "    if value<6000:\n",
    "        return 'Medium'\n",
    "    if value<18000:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'\n",
    "def map_travel(value):\n",
    "    if value==0:\n",
    "        return 'Zero'\n",
    "    if value<10000:\n",
    "        return 'Low'\n",
    "    if value<20000:\n",
    "        return 'Medium'\n",
    "    if value<40000:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'\n",
    "def map_lifestyle(value):\n",
    "    if value==0:\n",
    "        return 'Zero'\n",
    "    if value<0:\n",
    "        return 'Abysmal'\n",
    "    if value<1:\n",
    "        return 'Very Risky'\n",
    "    if value<5:\n",
    "        return 'Risky'\n",
    "    if value<10:\n",
    "        return 'Careful'\n",
    "    else:\n",
    "        return 'Very Careful'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Columns values</h1>\n",
    "\n",
    "<h3>Credit Score</h3>\n",
    "<ul>\n",
    "<li>'Poor' -> Credit Score from 0 to 580</li>\n",
    "<li>'Fair' -> Credit Score from 581 to 670</li>\n",
    "<li>'Good' -> Credit Score from 671 to 740</li>\n",
    "<li>'Very Good' -> Credit Score from 741</li>\n",
    "</ul>\n",
    "<h3>Savings</h3>\n",
    "<ul>\n",
    "<li>'Zero' -> No Savings</li>\n",
    "<li>'Very Low' -> less than 300000$ in savings</li>\n",
    "<li>'Low' -> savings betwwen 300001$ and 600000$</li>\n",
    "<li>'High' -> savings between 600001$ and 1200000$</li>\n",
    "<li>'Very High' -> more than 1200000$ in savings</li>\n",
    "</ul>\n",
    "<h3>Income</h3>\n",
    "<ul>\n",
    "<li>'Zero' -> No Income</li>\n",
    "<li>'Very Low' -> Income less than 40000$</li>\n",
    "<li>'Medium' -> Income between 40001$ and 100000$</li> \n",
    "<li>'High' -> Income between 100001$ and 200000$</li>\n",
    "<li>'Very High' -> Income more than 200000$</li>\n",
    "</ul>\n",
    "<h3>Debt</h3>\n",
    "<ul>\n",
    "<li>'Zero' -> No Debt</li>\n",
    "<li>'Very Low' -> Debt less than 50000$</li>\n",
    "<li>'Medium' -> Debt between 50001$ and 200000$</li> \n",
    "<li>'High' -> Debt between 200001$ and 750000$</li>\n",
    "<li>'Very High' -> Debt more than 750000$</li>\n",
    "</ul>\n",
    "<h3>Groceries</h3>\n",
    "<ul>\n",
    "<li>'Very Low' -> Expenses related to groceries less than 4000$</li>\n",
    "<li>'Medium' -> Expenses related to groceries between 4001$ and 12000$</li> \n",
    "<li>'High' -> Expenses related to groceries between 12001$ and 20000$</li>\n",
    "<li>'Very High' -> Expenses related to groceries more than 20000$</li>\n",
    "</ul>\n",
    "<h3>Clothing</h3>\n",
    "<ul>\n",
    "<li>'Low' -> Expenses related to clothing less than 1000$</li>\n",
    "<li>'Medium' -> Expenses related to clothing between 1001$ and 5000$</li> \n",
    "<li>'High' -> Expenses related to clothing between 5001$ and 10000$</li>\n",
    "<li>'Very High' -> Expenses related to clothing more than 10000$</li>\n",
    "</ul>\n",
    "<h3>Education</h3>\n",
    "<ul>\n",
    "<li>'Zero' -> No expenses related to education</li>\n",
    "<li>'Very Low' -> Expenses related to education less than 2000$</li>\n",
    "<li>'Medium' -> Expenses related to education between 2001$ and 6000$</li> \n",
    "<li>'High' -> Expenses related to education between 6001$ and 12000$</li>\n",
    "<li>'Very High' -> Expenses related to education more than 12000$</li>\n",
    "</ul>\n",
    "<h3>Entertainment</h3>\n",
    "<ul>\n",
    "<li>'Zero' -> No expenses related to entertainment</li>\n",
    "<li>'Very Low' -> Expenses related to entertainment less than 3000$</li>\n",
    "<li>'Medium' -> Expenses related to entertainment between 3001$ and 6000$</li> \n",
    "<li>'High' -> Expenses related to entertainment between 6001$ and 18000$</li>\n",
    "<li>'Very High' -> Expenses related to entertainment more than 18000$</li>\n",
    "</ul>\n",
    "<h3>Health</h3>\n",
    "<ul>\n",
    "<li>'Zero' -> No expenses related to health</li>\n",
    "<li>'Very Low' -> Expenses related to health less than 3000$</li>\n",
    "<li>'Medium' -> Expenses related to health between 3001$ and 6000$</li> \n",
    "<li>'High' -> Expenses related to health between 6001$ and 12000$</li>\n",
    "<li>'Very High' -> Expenses related to health more than 12000$</li>\n",
    "</ul>\n",
    "<h3>Housing</h3>\n",
    "<ul>\n",
    "<li>'Zero' -> No expenses related to housing</li>\n",
    "<li>'Very Low' -> Expenses related to housing less than 3000$</li>\n",
    "<li>'Medium' -> Expenses related to housing between 3001$ and 6000$</li> \n",
    "<li>'High' -> Expenses related to housing between 6001$ and 18000$</li>\n",
    "<li>'Very High' -> Expenses related to housing more than 18000$</li>\n",
    "</ul>\n",
    "<h3>Travel</h3>\n",
    "<ul>\n",
    "<li>'Zero' -> No expenses related to travelling</li>\n",
    "<li>'Very Low' -> Expenses related to travelling less than 10000$</li>\n",
    "<li>'Medium' -> Expenses related to travelling between 10001$ and 20000$</li> \n",
    "<li>'High' -> Expenses related to travelling between 20001$ and 40000$</li>\n",
    "<li>'Very High' -> Expenses related to travelling more than 40000$</li>\n",
    "</ul>\n",
    "<h3>Lifestyle</h3>\n",
    "<ul>\n",
    "<li>'Zero' -> The indiviudal has no money after the expenses</li>\n",
    "<li>'Abysmal' -> The individual is spending more than what they have</li>\n",
    "<li>'Very Risky' -> The individual has very little money after subtracting the expenses</li> \n",
    "<li>'Risky' -> The individual has little money after subtracting the expenses</li>\n",
    "<li>'Careful' -> The individual has a good margin subtracting the expenses</li>\n",
    "<li>'Very Careful' -> The individual has a very good margin subtracting the expenses</li>\n",
    "</ul>\n",
    "\n",
    "<p>The other features are not modified from the kaggle dataset<p>\n",
    "\n",
    "<h3>Gambling</h3>\n",
    "<ul>\n",
    "<li>'None' -> No gambling expenses</li>\n",
    "<li>'Low' -> Few gambling expenses</li>\n",
    "<li>'High' -> A lot of gambling expenses</li>\n",
    "</ul> \n",
    "<h3>Credit_Card</h3>\n",
    "<ul>\n",
    "<li>1 if the customer has a credit card, 0 otherwise</li>\n",
    "</ul>\n",
    "<h3>Mortgage</h3>\n",
    "<ul>\n",
    "<li>1 if the customer has a mortgage, 0 otherwise</li>\n",
    "</ul>\n",
    "<h3>Sav_accounts</h3>\n",
    "<ul>\n",
    "<li>1 if the customer has a savings account, 0 otherwise</li>\n",
    "</ul>\n",
    "<h3>Dependents</h3>\n",
    "<ul>\n",
    "<li>1 if the customer has dependents, 0 otherwise</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SAVINGS']=df['SAVINGS'].map(map_savings)\n",
    "df['CREDIT_SCORE']=df['CREDIT_SCORE'].map(map_credit_score)\n",
    "df['INCOME']=df['INCOME'].map(map_income)\n",
    "df['DEBT']=df['DEBT'].map(map_debt)\n",
    "df['T_GROCERIES_12']=df['T_GROCERIES_12'].map(map_groceries)\n",
    "df['T_CLOTHING_12']=df['T_CLOTHING_12'].map(map_clothing)\n",
    "df['T_EDUCATION_12']=df['T_EDUCATION_12'].map(map_education)\n",
    "df['T_ENTERTAINMENT_12']=df['T_ENTERTAINMENT_12'].map(map_entertainment)\n",
    "df['T_HEALTH_12']=df['T_HEALTH_12'].map(map_housing)\n",
    "df['T_HOUSING_12']=df['T_HOUSING_12'].map(map_housing)\n",
    "df['T_TRAVEL_12']=df['T_TRAVEL_12'].map(map_travel)\n",
    "df['LIFESTYLE']=df['LIFESTYLE'].map(map_lifestyle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'T_CLOTHING_12':'CLOTHING', 'T_EDUCATION_12':'EDUCATION', 'T_ENTERTAINMENT_12':'ENTERTAINMENT', 'T_GROCERIES_12':'GROCERIES', 'T_HEALTH_12':'HEALTH',\n",
    "           'T_HOUSING_12':'HOUSING', 'T_TRAVEL_12':'TRAVEL', 'CAT_GAMBLING':'GAMBLING', 'CAT_CREDIT_CARD':'CREDIT_CARD', 'CAT_MORTGAGE': 'MORTGAGE',\n",
    "           'CAT_SAVINGS_ACCOUNT':'SAV_ACCOUNT', 'CAT_DEPENDENTS':'DEPENDENTS'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "edges=[('INCOME','SAVINGS'),('SAV_ACCOUNT','SAVINGS'),\n",
    "                        ('SAVINGS','TRAVEL'),('SAVINGS','HOUSING'),('SAVINGS','HEALTH'),('SAVINGS','EDUCATION'),\n",
    "                        ('SAVINGS','GROCERIES'),('SAVINGS','CLOTHING'),('SAVINGS','ENTERTAINMENT'),\n",
    "                        ('INCOME','TRAVEL'),('INCOME','HOUSING'),('INCOME','HEALTH'),('INCOME','EDUCATION'),\n",
    "                        ('INCOME','GROCERIES'),('INCOME','CLOTHING'),('INCOME','ENTERTAINMENT'),\n",
    "                        ('DEBT','TRAVEL'),('DEBT','HOUSING'),('DEBT','HEALTH'),('DEBT','EDUCATION'),\n",
    "                        ('DEBT','GROCERIES'),('DEBT','CLOTHING'),('DEBT','ENTERTAINMENT'),\n",
    "                        ('DEPENDENTS','EDUCATION'),('DEPENDENTS','GROCERIES'),('DEPENDENTS','CLOTHING'),\n",
    "                        ('TRAVEL','LIFESTYLE'),('HOUSING','LIFESTYLE'),('HEALTH','LIFESTYLE'),('EDUCATION','LIFESTYLE'),\n",
    "                        ('GROCERIES','LIFESTYLE'),('CLOTHING','LIFESTYLE'),('ENTERTAINMENT','LIFESTYLE'),\n",
    "                        ('CREDIT_CARD','CREDIT_SCORE'),('LIFESTYLE','CREDIT_SCORE'),('DEBT','CREDIT_SCORE'),('GAMBLING','CREDIT_SCORE'),\n",
    "                        ('MORTGAGE','CREDIT_SCORE'),('DEPENDENTS','CREDIT_SCORE'),\n",
    "                        ('CREDIT_CARD','DEFAULT'),('LIFESTYLE','DEFAULT'),('DEBT','DEFAULT'),('GAMBLING','DEFAULT'),\n",
    "                        ('MORTGAGE','DEFAULT'),('DEPENDENTS','DEFAULT')]\n",
    "\n",
    "network=models.BayesianNetwork(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Network Structure</h3>\n",
    "<p>The Network is structured as follows:<br>\n",
    "Income, Debt and Savings account are not influenced by anything in the network, instead Savings is influenced by the income a person earn and if the person has or not a Savings account. The other variables not influenced by anything are the gambling predisposition, owning a Credit Card, the Mortgage and having depentents.<br>\n",
    "Instead the expenses are all influenced by the money a person can use and the debt they have, and the expenes influence the lifestyle of a person. The lifestyle, togheter with some of the non influenced factors determine the Credit Score and the Default of the costumer.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.fit(df)\n",
    "\n",
    "from pgmpy.factors.discrete.CPD import TabularCPD\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "def print_full(cpd):\n",
    "    backup = TabularCPD._truncate_strtable\n",
    "    TabularCPD._truncate_strtable = lambda self, x: x\n",
    "    print(cpd)\n",
    "    TabularCPD._truncate_strtable = backup\n",
    "\n",
    "with open('CPDs.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "         for cpd in network.get_cpds():\n",
    "            print(f'CPT of {cpd.variable}')\n",
    "            print_full(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The CPTs are generated in a file to prevent a non comprehensible output for the notebook, this strategy will be used for the tabular descriptions utilized in the following queries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining functions to execute queries with Variable Elimination\n",
    "def varElim(target, evidence, mode='Query'):\n",
    "    infer = VariableElimination(network)\n",
    "    if mode=='Query':\n",
    "        prob = infer.query([target], evidence=evidence, show_progress=False)\n",
    "    elif mode=='Map':\n",
    "        prob = infer.map_query([target], evidence=evidence, show_progress=False)\n",
    "    else:\n",
    "        return 'Error'\n",
    "    print('Probability of {} given {}'.format(target, evidence))\n",
    "    print(prob)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Query 1</h3>\n",
    "<p>In the first query we want to understand the probability of the output variables considering the disposable money of a costumer.<br>The tabular results are stored in the respective file.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inferring Credit Score and Default considering high savings values and high income values\n",
    "with open('Query1.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        varElim('DEFAULT', {'SAVINGS':'High', 'INCOME':'High'})\n",
    "        varElim('CREDIT_SCORE', {'SAVINGS':'High', 'INCOME':'High'})\n",
    "\n",
    "        print('\\n-----------------------------------------\\n')\n",
    "\n",
    "        varElim('DEFAULT', {'SAVINGS':'Very High', 'INCOME':'Very High'})\n",
    "        varElim('CREDIT_SCORE', {'SAVINGS':'Very High', 'INCOME':'Very High'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Looking at the results we can observe that the probability of DEFAULT being 1 are much less in the case of very high income and savings, respecting common belief, meaning in a really rational way that the more money a person can dispose of the more probable is for that person to repay their debt.<br> Observing instead the Credit Score tables we see a really similar distribution, we can observe a little difference, quite obvious, in the 'Poor' and 'Fair' distributions, where the customers with more disposable money have an higher probability of having a 'Fair' Credit Score.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Query 2</h3>\n",
    "<p>In this query we want to determine the most probable values of the variables Income, Savings and Debt to obtain a positive result (the costumer did not declare default and has a optimal credit score).<br> the results are shown below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of SAVINGS given {'CREDIT_SCORE': 'Very Good', 'DEFAULT': 0}\n",
      "{'SAVINGS': 'Very Low'}\n",
      "\n",
      "\n",
      "Probability of INCOME given {'CREDIT_SCORE': 'Very Good', 'DEFAULT': 0}\n",
      "{'INCOME': 'Very Low'}\n",
      "\n",
      "\n",
      "Probability of DEBT given {'CREDIT_SCORE': 'Very Good', 'DEFAULT': 0}\n",
      "{'DEBT': 'Very High'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inferring Savings, Debt and Income considering a very good Credit Score and not Default values\n",
    "varElim('SAVINGS', {'CREDIT_SCORE':'Very Good', 'DEFAULT':0}, mode='Map')\n",
    "print()\n",
    "varElim('INCOME', {'CREDIT_SCORE':'Very Good', 'DEFAULT':0}, mode='Map')\n",
    "print()\n",
    "varElim('DEBT', {'CREDIT_SCORE':'Very Good', 'DEFAULT':0}, mode='Map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this case the results reguarding the debt can be considered alligned with what we can expect because typically a lot of debt is associated with lots of different kinds of credit a person have, for example a good credit score considers martgages and other factors that usually cause debt to begin with.<br>The results reguarding savings and income are peculiar, that could be caused by a skewing of the data, in fact the data are not well balanced and this could influence the probabilities obtained by the fitting of the model.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Query 3</h3>\n",
    "<p>In this query we want to analize the effects of gambling when the lifestyle of a person is extremely expensive, showing the difference in the probability distribution of the credit score changing the value of the variable.<br>The tabular results are stored in the respective file.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inferring Credit Score considering a very risky lifestyle but no gambling or the same lifestyle with a low or high ammount of money spent in gambling\n",
    "with open('Query3.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        varElim('CREDIT_SCORE', {'LIFESTYLE':'Very Risky', 'GAMBLING':'High'})\n",
    "        print()\n",
    "        varElim('CREDIT_SCORE', {'LIFESTYLE':'Very Risky', 'GAMBLING':'Low'})\n",
    "        print()\n",
    "        varElim('CREDIT_SCORE', {'LIFESTYLE':'Very Risky', 'GAMBLING':'No'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The results of this query show that in case of extreme lifestyle gambling seems to be considered positively. The explanation could be that, considering that the total expenses are extremely high with respect to the disposable money, in such cases gambling could cause a win, and an increase of disposable money, not possible in other cases. Anyway from the probability distribution we can see that the better assignment is the 'Low' value, meaning that a great expense in gambling is penalized if compared to a moderate one.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Query 4</h3>\n",
    "<p>In the fourth query we want to analize the changing in the credit score probability distribution considering if a costumer has a mortgage and/or dependents.<br>The tabular results are stored in the respective file.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inferring Credit Score considering if the person has a mortgage and dependents\n",
    "with open('Query4.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        varElim('CREDIT_SCORE', {'MORTGAGE':0, 'DEPENDENTS':0})\n",
    "        print()\n",
    "        varElim('CREDIT_SCORE', {'MORTGAGE':1, 'DEPENDENTS':1})\n",
    "        print()\n",
    "        varElim('CREDIT_SCORE', {'MORTGAGE':0, 'DEPENDENTS':1})\n",
    "        print()\n",
    "        varElim('CREDIT_SCORE', {'MORTGAGE':1, 'DEPENDENTS':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>These results show that having assets is considered very positively for the Credit Score, in fact it is quite evident that the worst situation is the one with neither the mortgage or dependents.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Query 5</h3>\n",
    "<p>In the fifth query we observe the most probable assignements for the expenses considered the average american income.<br>The results are shown below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering the mean america income (60.000$):\n",
      "Probability of GROCERIES given {'INCOME': 'Medium'}\n",
      "{'GROCERIES': 'Medium'}\n",
      "\n",
      "\n",
      "Probability of HEALTH given {'INCOME': 'Medium'}\n",
      "{'HEALTH': 'Low'}\n",
      "\n",
      "\n",
      "Probability of HOUSING given {'INCOME': 'Medium'}\n",
      "{'HOUSING': 'Zero'}\n",
      "\n",
      "\n",
      "Probability of TRAVEL given {'INCOME': 'Medium'}\n",
      "{'TRAVEL': 'High'}\n",
      "\n",
      "\n",
      "Probability of CLOTHING given {'INCOME': 'Medium'}\n",
      "{'CLOTHING': 'Medium'}\n",
      "\n",
      "\n",
      "Probability of EDUCATION given {'INCOME': 'Medium'}\n",
      "{'EDUCATION': 'Zero'}\n",
      "\n",
      "\n",
      "Probability of ENTERTAINMENT given {'INCOME': 'Medium'}\n",
      "{'ENTERTAINMENT': 'High'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Some other interesting inferences\n",
    "#Inferences considering the mean american income (60.000$)\n",
    "print('Considering the mean america income (60.000$):') \n",
    "varElim('GROCERIES', {'INCOME':'Medium'}, mode='Map') \n",
    "print()\n",
    "varElim('HEALTH', {'INCOME':'Medium'}, mode='Map')\n",
    "print() \n",
    "varElim('HOUSING', {'INCOME':'Medium'}, mode='Map') \n",
    "print()\n",
    "varElim('TRAVEL', {'INCOME':'Medium'}, mode='Map')\n",
    "print()\n",
    "varElim('CLOTHING', {'INCOME':'Medium'}, mode='Map')\n",
    "print()\n",
    "varElim('EDUCATION', {'INCOME':'Medium'}, mode='Map')\n",
    "print()\n",
    "varElim('ENTERTAINMENT', {'INCOME':'Medium'}, mode='Map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Query 6</h3>\n",
    "<p>In the sixth query we want to observe how having a savings account influences the default of a costumer.<br>The tabular results are shown below becuase the output is small.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of DEFAULT given {'SAV_ACCOUNT': 1}\n",
      "+------------+----------------+\n",
      "| DEFAULT    |   phi(DEFAULT) |\n",
      "+============+================+\n",
      "| DEFAULT(0) |         0.5980 |\n",
      "+------------+----------------+\n",
      "| DEFAULT(1) |         0.4020 |\n",
      "+------------+----------------+\n",
      "\n",
      "Probability of DEFAULT given {'SAV_ACCOUNT': 0}\n",
      "+------------+----------------+\n",
      "| DEFAULT    |   phi(DEFAULT) |\n",
      "+============+================+\n",
      "| DEFAULT(0) |         0.5741 |\n",
      "+------------+----------------+\n",
      "| DEFAULT(1) |         0.4259 |\n",
      "+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inferring default considering if the person has a savings account or not\n",
    "varElim('DEFAULT', {'SAV_ACCOUNT':1})\n",
    "varElim('DEFAULT', {'SAV_ACCOUNT':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Query 7</h3>\n",
    "<p>In the last query we want to observe how the CREDIT_CARD value influences the default  and credit score of a costumer.<br>The tabular results are stored in the respective file.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inferring Default and Credit Score considering if a person has a credit card\n",
    "with open('Query7.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        varElim('CREDIT_SCORE', {'CREDIT_CARD':0})\n",
    "        print()\n",
    "        varElim('CREDIT_SCORE', {'CREDIT_CARD':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The last query offers a really interesting observation: we can actually notice that, as we expected, the Credit Score is highly inlfuenced by the CREDIT_CARD variable.<br>The Credit Card value 1 offers in fact a distribution where the probabilities of the high and low values ('Very High', 'High' and 'Poor') increse. That is due to the use of the credit cards, in fact having a credit card and using it properly will increase your Credit Score, but maxing out the credit limit or having similar behaviour will instead decrease your final Credit Score.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conclusions</h3>\n",
    "<p>Looking at the results of the queries we can observe that the network is giving results quite alligned with the expectations, despite some results are not what we would expect. The network could be made better considering more evenly distributed data (in some cases where present only 2 elements, generating a non accurate fitting) and discussing the model with an expert, to refine the network and his edges and to have a precise insight of the causal links between variables. Also this network wants to define causal links between elements that influence the credit score, but these are not the only ones that determine it and expanding the network to consider more elements could improve the effectiveness significantly.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
